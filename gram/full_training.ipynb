{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = torch.DiskFile('dat/facies_vectors.t7', 'r')\n",
    "facies = file:readObject()\n",
    "file:close()\n",
    "file = torch.DiskFile('dat/validation_data_nofacies.t7', 'r')\n",
    "validate = file:readObject()\n",
    "file:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "facies size: \t4149\tx\t9\t\n",
       "validate size: \t830\tx\t8\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- build tables\n",
    "print(\"facies size: \", facies:size()[1], \"x\", facies:size()[2])\n",
    "print(\"validate size: \", validate:size()[1], \"x\", validate:size()[2])\n",
    "\n",
    "\t-- initialize\n",
    "training_data = {}\n",
    "val_data = {}\n",
    "depth = {}\n",
    "\n",
    "\t-- build the training wells into the table\n",
    "training_data[\"shrimplin\"] = facies[{{1,471},{3,9}}]\n",
    "training_data[\"alexander\"] = facies[{{472,937},{3,9}}]\n",
    "training_data[\"shankle\"] = facies[{{938,1386},{3,9}}]\n",
    "training_data[\"luke\"] = facies[{{1387,1847},{3,9}}]\n",
    "training_data[\"kimzey\"] = facies[{{1848,2286},{3,9}}]\n",
    "training_data[\"cross\"] = facies[{{2287,2787},{3,9}}]\n",
    "training_data[\"nolan\"] = facies[{{2788,3202},{3,9}}]\n",
    "training_data[\"recruit\"] = facies[{{3203,3282},{3,9}}]\n",
    "training_data[\"newby\"] = facies[{{3283,3745},{3,9}}]\n",
    "training_data[\"churchman\"] = facies[{{3746,4149},{3,9}}]\n",
    "\n",
    "    -- build the validation data into a table\n",
    "val_data[\"stuart\"] = validate[{{1,474},{2,8}}]\n",
    "val_data[\"crawford\"] = validate[{{475,830},{2,8}}]\n",
    "\n",
    "\t-- build a depth log for plotting\n",
    "depth[\"shrimplin\"] = facies[{{1,471},{2}}]\n",
    "depth[\"alexander\"] = facies[{{472,937},{2}}]\n",
    "depth[\"shankle\"] = facies[{{938,1386},{2}}]\n",
    "depth[\"luke\"] = facies[{{1387,1847},{2}}]\n",
    "depth[\"kimzey\"] = facies[{{1848,2286},{2}}]\n",
    "depth[\"cross\"] = facies[{{2287,2787},{2}}]\n",
    "depth[\"nolan\"] = facies[{{2788,3202},{2}}]\n",
    "depth[\"recruit\"] = facies[{{3203,3282},{2}}]\n",
    "depth[\"newby\"] = facies[{{3283,3745},{2}}]\n",
    "depth[\"churchman\"] = facies[{{3746,4149},{2}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  stuart : DoubleTensor - size: 474x7\n",
       "  crawford : DoubleTensor - size: 356x7\n",
       "}\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- normalize the data\n",
    "\t-- training data\n",
    "mean = {}\n",
    "stdv = {}\n",
    "\n",
    "for key,value in pairs(training_data) do --over each well\n",
    "    mean[key] = torch.Tensor(7)\n",
    "    stdv[key] = torch.Tensor(7)\n",
    "    for i = 1, 7 do --over each log\n",
    "        mean[key][i] = training_data[key][{{},{i}}]:mean()\n",
    "        training_data[key][{{},{i}}]:add(-mean[key][i])\n",
    "        \n",
    "        stdv[key][i] = training_data[key][{{},{i}}]:std()\n",
    "        training_data[key][{{},{i}}]:div(stdv[key][i])\n",
    "    end\n",
    "end\n",
    "\n",
    "    -- validation data\n",
    "mean = {}\n",
    "stdv = {}\n",
    "\n",
    "for key,value in pairs(val_data) do --over each well\n",
    "    mean[key] = torch.Tensor(7)\n",
    "    stdv[key] = torch.Tensor(7)\n",
    "    for i = 1, 7 do --over each log\n",
    "        mean[key][i] = val_data[key][{{},{i}}]:mean()\n",
    "        val_data[key][{{},{i}}]:add(-mean[key][i])\n",
    "        \n",
    "        stdv[key][i] = val_data[key][{{},{i}}]:std()\n",
    "        val_data[key][{{},{i}}]:div(stdv[key][i])\n",
    "    end\n",
    "end\n",
    "\n",
    "-- facies labels for training\n",
    "facies_labels = {}\n",
    "\n",
    "facies_labels[\"shrimplin\"] = facies[{{1,471},{1}}]\n",
    "facies_labels[\"alexander\"] = facies[{{472,937},{1}}]\n",
    "facies_labels[\"shankle\"] = facies[{{938,1386},{1}}]\n",
    "facies_labels[\"luke\"] = facies[{{1387,1847},{1}}]\n",
    "facies_labels[\"kimzey\"] = facies[{{1848,2286},{1}}]\n",
    "facies_labels[\"cross\"] = facies[{{2287,2787},{1}}]\n",
    "facies_labels[\"nolan\"] = facies[{{2788,3202},{1}}]\n",
    "facies_labels[\"recruit\"] = facies[{{3203,3282},{1}}]\n",
    "facies_labels[\"newby\"] = facies[{{3283,3745},{1}}]\n",
    "facies_labels[\"churchman\"] = facies[{{3746,4149},{1}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- build the neural net\n",
    "net = nn.Sequential()\n",
    "net:add(nn.Linear(7,200))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.Linear(200,50))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.Linear(50,9))\n",
    "net:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- test the net -> forward\n",
    "temp = torch.Tensor(7)\n",
    "for i = 1,7 do\n",
    "    temp[i] = training_data[\"shrimplin\"][1][i]\n",
    "end\n",
    "input = temp\n",
    "\n",
    "output = net:forward(input)\n",
    "\n",
    "-- zero gradients and initialize\n",
    "net:zeroGradParameters()\n",
    "\n",
    "gradInput = net:backward(input, torch.rand(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- define the loss function\n",
    "criterion = nn.ClassNLLCriterion()\n",
    "criterion:forward(output,facies_labels[\"shrimplin\"][1])\n",
    "\n",
    "gradients = criterion:backward(output, facies_labels[\"shrimplin\"][1])\n",
    "gradInput = net:backward(input, gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- condition the data\n",
    "trainset = {}\n",
    "\n",
    "\t-- the data\n",
    "trainset[\"data\"] = torch.Tensor(facies:size()[1],7) \n",
    "\n",
    "idx = 0\n",
    "for key,value in pairs(training_data) do\n",
    "    for i = 1,training_data[key]:size()[1] do\n",
    "        trainset[\"data\"][i + idx] = training_data[key][i]\n",
    "    end\n",
    "    idx = idx + training_data[key]:size()[1]\n",
    "end\n",
    "\n",
    "\t-- the answers\n",
    "trainset[\"facies\"] = torch.Tensor(facies:size()[1])\n",
    "\n",
    "idx = 0\n",
    "for key,value in pairs(facies_labels) do\n",
    "    for i = 1, facies_labels[key]:size()[1] do\n",
    "        trainset[\"facies\"][i + idx] = facies_labels[key][i]\n",
    "    end\n",
    "    idx = idx + facies_labels[key]:size()[1]\n",
    "end\n",
    "\n",
    "\n",
    "-- write index() and size() functions\n",
    "setmetatable(trainset, \n",
    "    {__index = function(t, i) \n",
    "                    return {t.data[i], t.facies[i]} \n",
    "                end}\n",
    ");\n",
    "\n",
    "function trainset:size() \n",
    "    return self.data:size(1) \n",
    "end\n",
    "\n",
    "-- condition the validation data\n",
    "valset = {}\n",
    "\n",
    "\t-- the data\n",
    "valset[\"data\"] = torch.Tensor(validate:size()[1],7) \n",
    "\n",
    "idx = 0\n",
    "for key,value in pairs(val_data) do\n",
    "    for i = 1,val_data[key]:size()[1] do\n",
    "        valset[\"data\"][i + idx] = val_data[key][i]\n",
    "    end\n",
    "    idx = idx + val_data[key]:size()[1]\n",
    "end\n",
    "\n",
    "-- eliminate NaNs\n",
    "nan_mask = trainset.data:ne(trainset.data)\n",
    "trainset.data[nan_mask] = 0\n",
    "nan_mask = valset.data:ne(valset.data)\n",
    "valset.data[nan_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "starting training\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.6750709765736\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.299995678854\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.187636072056\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.1256669887461\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.0868113130971\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.0605348770086\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.0410629133286\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.0254415338866\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.0121801044183\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.0004392567964\t"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.98970702478848\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.9798716089222\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.97080389415775\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.962333377686\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.95421214996677\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.94635089067152\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.93873328949925\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.93125379235851\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.92406292491902\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.91696004944953\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 0.91696004944953\t\n",
       "training time =\t10.339772939682\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- train the net\n",
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = .001\n",
    "trainer.maxIteration = 20\n",
    "\n",
    "print(\"starting training\")\n",
    "timer = torch.Timer()\n",
    "trainer:train(trainset)\n",
    "print(\"training time =\", timer:time().real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = torch.Tensor(valset.data:size()[1])\n",
    "for i = 1,valset.data:size()[1] do\n",
    "    local prediction = net:forward(valset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)\n",
    "    preds[i] = indices[1]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 830\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 3\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 4\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 9\n",
       " 9\n",
       " 9\n",
       " 9\n",
       " 9\n",
       " 9\n",
       " 9\n",
       " 9\n",
       " 9\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 2\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 7\n",
       " 6\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 8\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 9\n",
       " 9\n",
       " 9\n",
       " 9\n",
       " 9\n",
       " 9\n",
       " 9\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 8\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 8\n",
       " 8\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 8\n",
       " 9\n",
       " 9\n",
       " 9\n",
       " 9\n",
       " 9\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 8\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 7\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 4\n",
       " 4\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 5\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 5\n",
       " 5\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 5\n",
       " 5\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 6\n",
       " 6\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 4\n",
       " 4\n",
       " 4\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 4\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 2\n",
       " 2\n",
       " 5\n",
       " 8\n",
       " 8\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 8\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 3\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 4\n",
       " 4\n",
       " 7\n",
       " 7\n",
       " 8\n",
       " 6\n",
       " 5\n",
       " 5\n",
       " 4\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 7\n",
       " 7\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 7\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 8\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 6\n",
       " 8\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       "[torch.DoubleTensor of size 830]\n",
       "\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
